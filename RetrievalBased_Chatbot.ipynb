{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrseno/RetrievalBased-Chatbot/blob/main/RetrievalBased_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lqEsXRpVz7z"
      },
      "source": [
        "!pip install optuna\n",
        "!pip install transformers\n",
        "!pip install SentencePiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSzslNtYNP7q"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD4VtVeUcTuI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from transformers import *\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT2eHmxNAp4P"
      },
      "source": [
        "# train\n",
        "!gdown --id 1lct2GyNPE2UwI8geGXRha6j1yU8tksSw\n",
        "\n",
        "# valid\n",
        "!gdown --id 13wDQLk8mXorxghxWFNfhWvXPWPPI27dL\n",
        "\n",
        "# test\n",
        "!gdown --id 1St87-nfaqT5ZyiaDRY_NPy8PbRdTEPAY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEeLawlSDQ7J"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "valid = pd.read_csv('valid.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ6V00J_RT-I"
      },
      "source": [
        "MODEL_NAME = 'bert-base-uncased'\n",
        "MAX_LEN = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfA2mrI-b6xw"
      },
      "source": [
        "def prepare_dataset(data, tokenizer, max_len):\n",
        "\n",
        "  ids = []\n",
        "  masks = []\n",
        "  labels = []\n",
        "  token_ids = []\n",
        "\n",
        "  labels = []\n",
        "  \n",
        "  for row in data.itertuples():\n",
        "    text = row.Input + ' [SEP] ' + row.Output\n",
        "    inputs = tokenizer(text, None, max_length=max_len, padding='max_length', truncation=True, return_attention_mask=True, return_token_type_ids=True, add_special_tokens=True)\n",
        "    ids.append(inputs['input_ids'])\n",
        "    masks.append(inputs['attention_mask'])\n",
        "    token_ids.append(inputs['token_type_ids'])\n",
        "\n",
        "    labels.append(row.Label)\n",
        "\n",
        "  return {\n",
        "      'input_ids': ids,\n",
        "      'attention_mask': masks,\n",
        "      'token_type_ids': token_ids,\n",
        "      'labels': labels\n",
        "      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oFYFsevgZsF"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "training_set = prepare_dataset(train, tokenizer, MAX_LEN)\n",
        "validating_set = prepare_dataset(valid, tokenizer, MAX_LEN)\n",
        "testting_set = prepare_dataset(test, tokenizer, MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNpIsPOCJrRE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import * \n",
        "from tensorflow.keras import optimizers, losses, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTblNya1YyCq"
      },
      "source": [
        "def get_model(MAX_LEN, MODEL_NAME):\n",
        "\n",
        "  input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "  attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "  token_type_ids = Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "    \n",
        "  encoder = TFAutoModel.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "\n",
        "  pooler_outputs = encoder({\"input_ids\": input_ids, \"token_type_ids\": token_type_ids, \"attention_mask\": attention_mask}, training=True).pooler_output\n",
        "\n",
        "  dense_layer = Dense(256, activation='relu', name='dense_layer1')(pooler_outputs)\n",
        "  dropout = Dropout(0.25)(dense_layer)\n",
        "  output = Dense(1, activation='sigmoid')(dropout)\n",
        "    \n",
        "  model = Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=output)\n",
        "\n",
        "  optimizer = optimizers.Adam(lr=2e-5)\n",
        "  loss = losses.binary_crossentropy\n",
        "\n",
        "  model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtKrQCcyZerF"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_model(MAX_LEN, MODEL_NAME)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, to_file='./model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2pFWJi2JmTz"
      },
      "source": [
        "x_train = [np.array(training_set['input_ids'], dtype=int), np.array(training_set['attention_mask'], dtype=int), np.array(training_set['token_type_ids'], dtype=int)]\n",
        "x_valid = [np.array(validating_set['input_ids'], dtype=int), np.array(validating_set['attention_mask'], dtype=int), np.array(validating_set['token_type_ids'], dtype=int)]\n",
        "x_test = [np.array(testting_set['input_ids'], dtype=int), np.array(testting_set['attention_mask'], dtype=int), np.array(testting_set['token_type_ids'], dtype=int)]\n",
        "\n",
        "y_train = train.Label\n",
        "y_valid = valid.Label\n",
        "y_test = test.Label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R62c5yRYKIJL"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    epochs=3,\n",
        "    verbose=1,\n",
        "    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpgYNbLXbO8U"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz51vQubQSc"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46kEY99UGDse"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFLZO-aWG-BM"
      },
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "  sig_threshold = trial.suggest_float(\"sig_threshold\", 0.0, 1.0)\n",
        "  print(\"sig_threshold\", sig_threshold)\n",
        "\n",
        "  pred_labels = [1 if predictions[i] > sig_threshold else 0 for i in range(len(testting_set['labels']))]\n",
        "\n",
        "  acc = accuracy_score(testting_set['labels'], pred_labels)\n",
        "  print(\"acc\", acc)\n",
        "\n",
        "  return acc\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGlFOBgSY0ks"
      },
      "source": [
        "best_sig_threshold = study.best_value  \n",
        "\n",
        "pred_labels = [1 if predictions[i] > best_sig_threshold else 0 for i in range(len(testting_set['labels']))]\n",
        "\n",
        "print('Test Accuracy:', accuracy_score(testting_set['labels'], pred_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFwv1mAy5ufG"
      },
      "source": [
        "best_sig_threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4dSW1ZXFSWD"
      },
      "source": [
        "def find_group_of_questions(questions, labels):\n",
        "  \n",
        "  begins = []\n",
        "  ends = []\n",
        "  tag = []\n",
        "  i = 0\n",
        "  begins.append(i)\n",
        "  curr_ques = ''\n",
        "\n",
        "  for index in range(len(questions)):\n",
        "        question = questions[index]\n",
        "        tag.append(int(labels[index]))\n",
        "      \n",
        "        if i == 0:\n",
        "          curr_ques = question       \n",
        "        \n",
        "        if curr_ques != question:\n",
        "          curr_ques = question\n",
        "          ends.append(i)\n",
        "          begins.append(i)\n",
        "\n",
        "        i += 1\n",
        "  ends.append(i)\n",
        "\n",
        "  return begins, ends, tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExUAadOnFULe"
      },
      "source": [
        "def calculate_measures(predictions, labels):\n",
        "\n",
        "  predictions, labels = zip(*sorted(zip(predictions, labels), reverse=True))\n",
        "\n",
        "  rank = 0.0\n",
        "\n",
        "  for i in range(0, len(labels)):\n",
        "            \n",
        "    if labels[i] == 1:\n",
        "      if rank == 0.0:\n",
        "        rank = 1 / (i + 1)\n",
        "  \n",
        "  return rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pALHDHIFajC"
      },
      "source": [
        "def calculate_MAP_and_MRR(begins, ends, labels, predictions) :\n",
        "\n",
        "  tmp = []\n",
        "\n",
        "  for pred in predictions:\n",
        "    tmp.append(pred)\n",
        "\n",
        "  RR_s = []\n",
        "\n",
        "  for i in range (0, len(begins)):\n",
        "    begin = begins[i]\n",
        "    end = ends[i]\n",
        "\n",
        "    RR = calculate_measures(tmp[begin:end + 1], labels[begin:end + 1])\n",
        "\n",
        "    RR_s.append(RR)\n",
        "\n",
        "  return np.mean(RR_s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqrFfW4WPk9g"
      },
      "source": [
        "sorted_test = test.sort_values('Input')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmiEzWn6GWNs",
        "outputId": "38d3065a-3654-408d-b533-ee3a29a77721"
      },
      "source": [
        "begins, ends, labels = find_group_of_questions(sorted_test.Input, sorted_test.Label)\n",
        "MRR = calculate_MAP_and_MRR(begins, ends, labels, predictions)\n",
        "print(\"MRR:\", MRR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR: 0.740077157059129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_pqRn4y80U4"
      },
      "source": [
        "def prepare_test_dataset(data, tokenizer, max_len):\n",
        "\n",
        "  ids = []\n",
        "  masks = []\n",
        "  labels = []\n",
        "  token_ids = []\n",
        "  \n",
        "  for row in data.itertuples():\n",
        "    text = row.Input + ' [SEP] ' + row.Output\n",
        "    inputs = tokenizer(text, None, max_length=max_len, padding='max_length', truncation=True, return_attention_mask=True, return_token_type_ids=True, add_special_tokens=True)\n",
        "    ids.append(inputs['input_ids'])\n",
        "    masks.append(inputs['attention_mask'])\n",
        "    token_ids.append(inputs['token_type_ids'])\n",
        "\n",
        "  return {\n",
        "      'input_ids': ids,\n",
        "      'attention_mask': masks,\n",
        "      'token_type_ids': token_ids,\n",
        "      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-ejyDnXDlB9"
      },
      "source": [
        "extra_test = pd.DataFrame([['what do you do for your weekend?', 'i am not quite sure yet . i like to go shopping.'],\n",
        "                           ['i am not quite sure yet . i like to go shopping.', 'well , i am not sure what you are doing.'],\n",
        "                           ['well , i am not sure what you are doing.', 'i am not sure . i am not quite sure yet.'], \n",
        "                           ['i am not sure . i am not quite sure yet.', 'well , i am not sure if you are interested , you would not have been fired.'],\n",
        "                           ['well , i am not sure if you are interested , you would not have been fired.', 'i am sorry , but i cannot . i have got a sore throat.'],\n",
        "                           ['i am sorry , but i cannot . i have got a sore throat.', 'oh , i see . but i have never been here before . i have been looking for a long time . it is really a nice neighborhood here.'],\n",
        "                           ['oh , i see . but i have never been here before . i have been looking for a long time . it is really a nice neighborhood here.', 'i really appreciate your help.'],\n",
        "                           ['i really appreciate your help.', 'thank you . i really appreciate your help.'],\n",
        "                           ['thank you . i really appreciate your help.', 'you are welcome . i hope you will enjoy your rest and hope to make up.'], \n",
        "                           ['you are welcome . i hope you will enjoy your rest and hope to make up.', 'thank you . i will try to keep it to my li.'],\n",
        "                           ['how are you?', 'Well, I love going to the cinema.'],\n",
        "                           ['what do you want to eat?', 'I want to drink coffee.'],\n",
        "                           ['what is your favorite color?', 'study.'],\n",
        "                           ['what is your favorite color?', 'pink.'],\n",
        "                           ['Where have you been?', 'i lived in england when i was at the conference . i always wanted to go out dancing.'],\n",
        "                           ['Do you consider yourself a good mother?', 'Yes , I am a very good mother and successful career woman.'],\n",
        "                           ['Yes , I am a very good mother and successful career woman.', 'How can you manage to do both ?'],\n",
        "                           ['How can you manage to do both ?', 'I have a good manager.'],\n",
        "                           ['I have a good manager.', 'How was your first day at work?'],\n",
        "                           ['How was your first day at work?', 'I do not know.'],\n",
        "                           ['I do not know.', 'great.'],\n",
        "                           ['great.', 'I think the most important thing is that you should be nice to yourself.'],\n",
        "                           ['I think the most important thing is that you should be nice to yourself.', 'Yeah, that is right.'],\n",
        "                           ['Yeah, that is right.', 'You can only be nice to others when you can be nice to yourself.'],\n",
        "                           ['You can only be nice to others when you can be nice to yourself.', 'I have two nice sisters.'],\n",
        "                           ['I have two nice sisters.', 'Is he very understanding and supportive?']], \n",
        "                          columns=[\"Input\", \"Output\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZAeh-q59NUI"
      },
      "source": [
        "extra_testting_set = prepare_test_dataset(extra_test, tokenizer, MAX_LEN)\n",
        "extra_prepared_test = [np.array(extra_testting_set['input_ids'], dtype=int), np.array(extra_testting_set['attention_mask'], dtype=int), np.array(extra_testting_set['token_type_ids'], dtype=int)]\n",
        "\n",
        "predictions = model.predict(extra_prepared_test)\n",
        "\n",
        "pred_labels = [1 if predictions[i] > best_sig_threshold else 0 for i in range(len(predictions))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o1kREghGP6O"
      },
      "source": [
        "for index, row in extra_test.iterrows():\n",
        "\n",
        "  print(\"Input:\", row.Input)\n",
        "  print(\"Output:\", row.Output)\n",
        "\n",
        "  if pred_labels[index]:\n",
        "    print(\"IsNext.\")\n",
        "  else:\n",
        "    print(\"NotNext\")\n",
        "\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wMjgCKIUFwa"
      },
      "source": [
        "# search space\n",
        "!gdown --id 1TtUSvIUjIF7mz49ZVTw7lt2fXQ726vaa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhkCj3DcZsNV"
      },
      "source": [
        "test_inp = [\"how are you?\", \"what do you want to eat?\", \"what is your favorite color?\", \n",
        "            \"where have you been?\", \"do you consider yourself a good mother?\", \"I have two nice sisters.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weHW4cS6Ukoq"
      },
      "source": [
        "with open(\"SearchSpace.txt\") as f:\n",
        "  unique_out = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L59yPXJ0-eA6"
      },
      "source": [
        "test = []\n",
        "\n",
        "for inp in test_inp:\n",
        "  for out in unique_out:\n",
        "    test.append([inp, out.strip()])\n",
        "\n",
        "extra_test = pd.DataFrame(test, columns=[\"Input\", \"Output\"])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyw4Xhew_fuo"
      },
      "source": [
        "extra_testting_set = prepare_test_dataset(extra_test, tokenizer, MAX_LEN)\n",
        "extra_prepared_test = [np.array(extra_testting_set['input_ids'], dtype=int), np.array(extra_testting_set['attention_mask'], dtype=int), np.array(extra_testting_set['token_type_ids'], dtype=int)]\n",
        "\n",
        "predictions = model.predict(extra_prepared_test)\n",
        "extra_test[\"Score\"] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJYGYQXMdnJ"
      },
      "source": [
        "answer = extra_test.groupby(\"Input\").apply(lambda x: x.sort_values(ascending=False, by='Score').head(1))\n",
        "answer.reset_index(drop=True, inplace=True)\n",
        "answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOtznoeucbOj"
      },
      "source": [
        "for index, row in answer.iterrows():\n",
        "  print(\"Input:\", row.Input)\n",
        "  print(\"Output:\", row.Output)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}